{
 "cells": [
  {
   "cell_type": "code",
   "execution_count": 10,
   "metadata": {},
   "outputs": [],
   "source": [
    "def byte2str(n, d = 2):\n",
    "    s = 'B'\n",
    "    if n >= 1024:\n",
    "        n/=1024\n",
    "        s = 'K'\n",
    "    if n >= 1024:\n",
    "        n/=1024\n",
    "        s = 'M'\n",
    "    if n >= 1024:\n",
    "        n/=1024\n",
    "        s = 'G'\n",
    "    if n >= 1024:\n",
    "        n/=1024\n",
    "        s = 'T'\n",
    "    return '{:.2f}{}'.format(n,s)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 2,
   "metadata": {},
   "outputs": [],
   "source": [
    "dic = {'name': 'MIB',\n",
    "'details': {'cpu':'XEON E5 6666','cpu_cores':8, 'memory':\"16GB*4&2666MHz\",'gpu':'RTX 2080 Ti*2'},\n",
    "'timeStamp': 1932846198,\n",
    "'cpu_total': 0.73,\n",
    "'cpu_per_core': [0.0,0.43,0.45,0.56,0.89,0.01,0.01,0.02],\n",
    "'memory_status': '562M/38.0G',\n",
    "'memory_percentage': 0.07,\n",
    "'top_cpu_user': 'agent_h',\n",
    "'gpu_status':[\n",
    "                {\n",
    "                'gpu_no': 0,\n",
    "                'gpu_name': 'RTX 2080 Ti',\n",
    "                'gpu_memory_status': '12M/8119M',\n",
    "                'gpu_util': 0.78,\n",
    "                'gpu_memory': 0.23,\n",
    "                'gpu_temperature': 48,\n",
    "                'top_gpu_user': 'agent_n',\n",
    "                },\n",
    "                {\n",
    "                'gpu_no': 1,\n",
    "                'gpu_name': 'RTX 2080 Ti',\n",
    "                'gpu_memory_status': '3434M/8119M',\n",
    "                'gpu_util': 0.33,\n",
    "                'gpu_memory': 0.75,\n",
    "                'gpu_temperature': 78,\n",
    "                'top_gpu_user': 'alien_z',\n",
    "                }\n",
    "            ]\n",
    "}"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 1,
   "metadata": {},
   "outputs": [],
   "source": [
    "import psutil"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "### timeStamp"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "### cpu_total"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 35,
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/plain": [
       "43.1"
      ]
     },
     "execution_count": 35,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "psutil.cpu_percent(interval=.5, percpu=False)"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "### cpu_per_core"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 3,
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/plain": [
       "[0.0,\n",
       " 0.0,\n",
       " 0.0,\n",
       " 0.0,\n",
       " 0.0,\n",
       " 0.0,\n",
       " 0.0,\n",
       " 0.0,\n",
       " 0.0,\n",
       " 0.0,\n",
       " 0.0,\n",
       " 0.0,\n",
       " 0.0,\n",
       " 0.0,\n",
       " 0.0,\n",
       " 0.0]"
      ]
     },
     "execution_count": 3,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "psutil.cpu_percent(interval=.5, percpu=True)"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "### memory_status"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 11,
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/plain": [
       "'800.09M/38.99G'"
      ]
     },
     "execution_count": 11,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "'{}/{}'.format(byte2str(psutil.virtual_memory().used),byte2str(psutil.virtual_memory().total))"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "### memory_percentage"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 36,
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/plain": [
       "10.4"
      ]
     },
     "execution_count": 36,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "psutil.virtual_memory().percent"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 39,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "agent_h:python:412.0%\n"
     ]
    }
   ],
   "source": [
    "def get_plist():\n",
    "    p_list = []\n",
    "    p_list_dict = {}\n",
    "    for i in psutil.process_iter():\n",
    "    #     print(i.as_dict())\n",
    "        p_list.append((i.as_dict()['cpu_percent'],i.as_dict()['username'],i.as_dict()['name']))\n",
    "        p_list_dict[str(i.as_dict()['pid'])]=(i.as_dict()['cpu_percent'],i.as_dict()['username'],i.as_dict()['name'])\n",
    "    return p_list,p_list_dict\n",
    "p_list,p_list_dict=get_plist()\n",
    "print('{}:{}:{}%'.format(sorted(p_list)[-1][1],sorted(p_list)[-1][2],sorted(p_list)[-1][0]))\n",
    "# print(sorted(p_list)[::-1])\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 22,
   "metadata": {},
   "outputs": [],
   "source": [
    "from pynvml import *\n",
    "nvmlInit()"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 28,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Driver Version: b'430.40'\n",
      "Device 0 : b'GeForce RTX 2080 Ti'\n",
      "Temp 0 ; 45\n",
      "gpu_util 0 : 98\n",
      "gpu_mem_util 0 : 61.68928767915785\n",
      "gpu_total_mem 0 : 10.76G\n",
      "gpu_used_mem 0 : 6.64G\n",
      "agent_h:python:6.62G\n",
      "Device 1 : b'GeForce RTX 2080 Ti'\n",
      "Temp 1 ; 30\n",
      "gpu_util 1 : 0\n",
      "gpu_mem_util 1 : 0.15257130865345894\n",
      "gpu_total_mem 1 : 10.76G\n",
      "gpu_used_mem 1 : 16.81M\n",
      "None\n"
     ]
    }
   ],
   "source": [
    "from pynvml import *\n",
    "nvmlInit()\n",
    "print(\"Driver Version:\", nvmlSystemGetDriverVersion())\n",
    "deviceCount = nvmlDeviceGetCount()\n",
    "for i in range(deviceCount):\n",
    "    handle = nvmlDeviceGetHandleByIndex(i)\n",
    "    print(\"Device\", i, \":\", nvmlDeviceGetName(handle))\n",
    "    print(\"Temp\",i,\";\",nvmlDeviceGetTemperature(handle,0))\n",
    "    print(\"gpu_util\", i, \":\", nvmlDeviceGetUtilizationRates(handle).gpu)\n",
    "    print(\"gpu_mem_util\", i, \":\", 100*nvmlDeviceGetMemoryInfo(handle).used/nvmlDeviceGetMemoryInfo(handle).total)\n",
    "    print(\"gpu_total_mem\", i, \":\", byte2str(nvmlDeviceGetMemoryInfo(handle).total))\n",
    "    print(\"gpu_used_mem\", i, \":\", byte2str(nvmlDeviceGetMemoryInfo(handle).used))\n",
    "    procs = nvmlDeviceGetComputeRunningProcesses(handle)\n",
    "    \n",
    "    mem = -1\n",
    "    user = None\n",
    "    for p in procs:\n",
    "        if p.usedGpuMemory > mem:\n",
    "            user = '{}:{}:{}'.format(p_list_dict[str(p.pid)][1],\n",
    "                                     p_list_dict[str(p.pid)][2],\n",
    "                                     byte2str(p.usedGpuMemory))\n",
    "    print(user)\n",
    "\n",
    "\n",
    "#     print(handle)\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 71,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "[{'gpu_no': 0, 'gpu_name': 'GeForce RTX 2080 Ti', 'gpu_memory_status': '4.80G/10.76G', 'gpu_util': 100, 'gpu_memory': 44.61, 'gpu_temperature': 46, 'top_gpu_user': 'agent_h:python:4.78G'}, {'gpu_no': 1, 'gpu_name': 'GeForce RTX 2080 Ti', 'gpu_memory_status': '16.81M/10.76G', 'gpu_util': 0, 'gpu_memory': 0.15, 'gpu_temperature': 31, 'top_gpu_user': None}]\n"
     ]
    }
   ],
   "source": [
    "def get_gpu_status(p_list_dict):\n",
    "    gpu_status_list = []\n",
    "    nvmlInit()\n",
    "    deviceCount = nvmlDeviceGetCount()\n",
    "    for i in range(deviceCount):\n",
    "        handle = nvmlDeviceGetHandleByIndex(i)\n",
    "        procs = nvmlDeviceGetComputeRunningProcesses(handle)\n",
    "        mem = 0\n",
    "        user = None\n",
    "        for p in procs:\n",
    "            if p.usedGpuMemory > mem:\n",
    "                user = '{}:{}:{}'.format(p_list_dict[str(p.pid)][1],\n",
    "                                         p_list_dict[str(p.pid)][2],\n",
    "                                         byte2str(p.usedGpuMemory))\n",
    "        status = {\n",
    "                       'gpu_no': i,\n",
    "                       'gpu_name': nvmlDeviceGetName(handle).decode('utf-8'),\n",
    "                       'gpu_memory_status': '{}/{}'.format(byte2str(nvmlDeviceGetMemoryInfo(handle).used),byte2str(nvmlDeviceGetMemoryInfo(handle).total)),\n",
    "                       'gpu_util': nvmlDeviceGetUtilizationRates(handle).gpu,\n",
    "                       'gpu_memory': round(100*nvmlDeviceGetMemoryInfo(handle).used/nvmlDeviceGetMemoryInfo(handle).total,2),\n",
    "                       'gpu_temperature': nvmlDeviceGetTemperature(handle,0),\n",
    "                       'top_gpu_user': user,\n",
    "                   }\n",
    "        gpu_status_list.append(status)\n",
    "    return gpu_status_list\n",
    "print(get_gpu_status(p_list_dict))"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 72,
   "metadata": {},
   "outputs": [],
   "source": [
    "import time\n",
    "def get_sys_info():\n",
    "    sys_dic = {'name': 'MIB',\n",
    "               'details': {'cpu':'XEON E5 6666','cpu_cores':8, 'memory':\"16GB*4&2666MHz\",'gpu':'RTX 2080 Ti*2'},\n",
    "               'timestamp': 1932846198,\n",
    "               'cpu_total': 0.73,\n",
    "               'cpu_per_core': [0.0,0.43,0.45,0.56,0.89,0.01,0.01,0.02],\n",
    "               'memory_status': '562M/38.0G',\n",
    "               'memory_percentage': 0.07,\n",
    "               'top_cpu_user': 'agent_h',\n",
    "               'gpu_status':[\n",
    "                   {\n",
    "                       'gpu_no': 0,\n",
    "                       'gpu_name': 'RTX 2080 Ti',\n",
    "                       'gpu_memory_status': '12M/8119M',\n",
    "                       'gpu_util': 0.78,\n",
    "                       'gpu_memory': 0.23,\n",
    "                       'gpu_temperature': 48,\n",
    "                       'top_gpu_user': 'agent_n',\n",
    "                   },\n",
    "                   {\n",
    "                       'gpu_no': 1,\n",
    "                       'gpu_name': 'RTX 2080 Ti',\n",
    "                       'gpu_memory_status': '3434M/8119M',\n",
    "                       'gpu_util': 0.33,\n",
    "                       'gpu_memory': 0.75,\n",
    "                       'gpu_temperature': 78,\n",
    "                       'top_gpu_user': 'alien_z',\n",
    "                   }\n",
    "               ]\n",
    "              }\n",
    "    sys_dic['timestamp']=time.time()\n",
    "    sys_dic['cpu_total']=psutil.cpu_percent(interval=.5, percpu=False)\n",
    "    sys_dic['cpu_per_core']=psutil.cpu_percent(interval=.5, percpu=True)\n",
    "    sys_dic['memory_status']='{}/{}'.format(byte2str(psutil.virtual_memory().used),byte2str(psutil.virtual_memory().total))\n",
    "    sys_dic['memory_percentage'] = psutil.virtual_memory().percent\n",
    "    p_list,p_list_dict=get_plist()\n",
    "    sys_dic['top_cpu_user']='{}:{}:{}%'.format(sorted(p_list)[-1][1],sorted(p_list)[-1][2],sorted(p_list)[-1][0])\n",
    "    sys_dic['gpu_status']=get_gpu_status(p_list_dict)\n",
    "    sys_dic['details']={'cpu':platform.processor(),\n",
    "                        'cpu_cores':str(len(sys_dic['cpu_per_core'])),\n",
    "                        'memory':byte2str(psutil.virtual_memory().total),\n",
    "                        'gpu':[x['gpu_name'] for x in sys_dic['gpu_status']]\n",
    "                                          \n",
    "    }\n",
    "    return sys_dic\n",
    "    "
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 73,
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/plain": [
       "{'name': 'MIB',\n",
       " 'details': {'cpu': 'x86_64',\n",
       "  'cpu_cores': '16',\n",
       "  'memory': '38.99G',\n",
       "  'gpu': ['GeForce RTX 2080 Ti', 'GeForce RTX 2080 Ti']},\n",
       " 'timestamp': 1567782748.407056,\n",
       " 'cpu_total': 29.7,\n",
       " 'cpu_per_core': [12.2,\n",
       "  12.0,\n",
       "  100.0,\n",
       "  2.0,\n",
       "  100.0,\n",
       "  0.0,\n",
       "  0.0,\n",
       "  0.0,\n",
       "  0.0,\n",
       "  0.0,\n",
       "  0.0,\n",
       "  13.7,\n",
       "  12.0,\n",
       "  12.0,\n",
       "  14.0,\n",
       "  13.7],\n",
       " 'memory_status': '3.54G/38.99G',\n",
       " 'memory_percentage': 10.6,\n",
       " 'top_cpu_user': 'agent_h:python:435.7%',\n",
       " 'gpu_status': [{'gpu_no': 0,\n",
       "   'gpu_name': 'GeForce RTX 2080 Ti',\n",
       "   'gpu_memory_status': '4.80G/10.76G',\n",
       "   'gpu_util': 99,\n",
       "   'gpu_memory': 44.61,\n",
       "   'gpu_temperature': 46,\n",
       "   'top_gpu_user': 'agent_h:python:4.78G'},\n",
       "  {'gpu_no': 1,\n",
       "   'gpu_name': 'GeForce RTX 2080 Ti',\n",
       "   'gpu_memory_status': '16.81M/10.76G',\n",
       "   'gpu_util': 0,\n",
       "   'gpu_memory': 0.15,\n",
       "   'gpu_temperature': 31,\n",
       "   'top_gpu_user': None}]}"
      ]
     },
     "execution_count": 73,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "get_sys_info()"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 77,
   "metadata": {},
   "outputs": [],
   "source": [
    "import platform\n",
    "import json\n",
    "import requests"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 80,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "{\n",
      "  \"message\": \"add machien info successfully\", \n",
      "  \"status\": true\n",
      "}\n",
      "\n"
     ]
    }
   ],
   "source": [
    "dic = get_sys_info()\n",
    "data = json.dumps(dic)\n",
    "url = 'http://localhost:5000/add_machine'\n",
    "header = {'Content-Type': \"application/json\"}\n",
    "response = requests.post(url, data=data, headers=header)\n",
    "print(response.content.decode('utf-8'))\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 82,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "[\n",
      "  {\n",
      "    \"cpu_per_core\": [\n",
      "      76.5, \n",
      "      0.0, \n",
      "      0.0, \n",
      "      98.0, \n",
      "      0.0, \n",
      "      78.4, \n",
      "      2.0, \n",
      "      80.0, \n",
      "      2.0, \n",
      "      76.0, \n",
      "      78.0, \n",
      "      2.0, \n",
      "      78.0, \n",
      "      2.0, \n",
      "      77.6, \n",
      "      2.0\n",
      "    ], \n",
      "    \"cpu_total\": 81.5, \n",
      "    \"details\": {\n",
      "      \"cpu\": \"x86_64\", \n",
      "      \"cpu_cores\": \"16\", \n",
      "      \"gpu\": [\n",
      "        \"GeForce RTX 2080 Ti\", \n",
      "        \"GeForce RTX 2080 Ti\"\n",
      "      ], \n",
      "      \"memory\": \"38.99G\"\n",
      "    }, \n",
      "    \"gpu_status\": [\n",
      "      {\n",
      "        \"gpu_memory\": 24.26, \n",
      "        \"gpu_memory_status\": \"2.61G/10.76G\", \n",
      "        \"gpu_name\": \"GeForce RTX 2080 Ti\", \n",
      "        \"gpu_no\": 0, \n",
      "        \"gpu_temperature\": 45, \n",
      "        \"gpu_util\": 100, \n",
      "        \"top_gpu_user\": \"agent_h:python:2.59G\"\n",
      "      }, \n",
      "      {\n",
      "        \"gpu_memory\": 0.15, \n",
      "        \"gpu_memory_status\": \"16.81M/10.76G\", \n",
      "        \"gpu_name\": \"GeForce RTX 2080 Ti\", \n",
      "        \"gpu_no\": 1, \n",
      "        \"gpu_temperature\": 32, \n",
      "        \"gpu_util\": 0, \n",
      "        \"top_gpu_user\": null\n",
      "      }\n",
      "    ], \n",
      "    \"memory_percentage\": 10.4, \n",
      "    \"memory_status\": \"3.45G/38.99G\", \n",
      "    \"name\": \"MIB\", \n",
      "    \"timestamp\": \"2019-09-06 11:43:59.067042\", \n",
      "    \"top_cpu_user\": \"agent_h:python:428.8%\"\n",
      "  }\n",
      "]\n",
      "\n"
     ]
    }
   ],
   "source": [
    "url = 'http://127.0.0.1:5000/get_machines'\n",
    "response = requests.get(url)\n",
    "print(response.content.decode('utf-8'))"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "data = json.dumps(dic)\n",
    "url = 'http://127.0.0.1:5000/add_machine'\n",
    "header = {'Content-Type': \"application/json\"}\n",
    "response = requests.post(url, data=data, headers=header)\n",
    "print(response.content.decode('utf-8'))\n",
    "url = 'http://127.0.0.1:5000/get_machines'\n",
    "response = requests.get(url)\n",
    "print(response.content.decode('utf-8'))"
   ]
  }
 ],
 "metadata": {
  "kernelspec": {
   "display_name": "Python 3",
   "language": "python",
   "name": "python3"
  },
  "language_info": {
   "codemirror_mode": {
    "name": "ipython",
    "version": 3
   },
   "file_extension": ".py",
   "mimetype": "text/x-python",
   "name": "python",
   "nbconvert_exporter": "python",
   "pygments_lexer": "ipython3",
   "version": "3.7.4"
  }
 },
 "nbformat": 4,
 "nbformat_minor": 2
}
